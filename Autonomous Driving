import git
from imgaug import augmenters as iaa
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import keras
import random
import chumpy as cu
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.optimizers import Adam
from keras.utils.np_utils import to_categorical
from keras.layers.convolutional import Conv2D, MaxPooling2D
import pandas as pd
import cv2
import os
import ntpath
from sklearn.utils import shuffle
from sklearn.model_selection import train_test_split



path = 'C:\\Users\\HP\\PycharmProjects\\IP\\Traffic Data'
clone = 'https://github.com/BodduRaviteja/UdacitySimulatorTrack.git'
g = git.Git(path).clone(clone)


#dataframe object
datdir = 'UdacitySimulatorTrack'
columns = ['center', 'left', 'right', 'steering', 'throttle', 'reverse', 'speed']
data = pd.read_csv(os.path.join('C:\\Users\\HP\\PycharmProjects\\IP\\Cardata_BC\\driving_log.csv'), names = columns)
#pd.set_option('display.max_colwidth', -1) #prevents the overflow or helps in proper display of the end result on the output console
#data.style.set_properties(subset= ['center', 'left', 'right', 'steering', 'throttle', 'reverse', 'speed'], **{'width' : '500px'})
#print(data.head()) #returns first 5 rows of the sheet



#for extracting the tail end of the image name instead of total address of the each image
def path_leaf(path):
    head, tail = ntpath.split((path))
    return tail
data['center'] = data['center'].apply(path_leaf)
data['left'] = data['left'].apply(path_leaf)
data['right'] = data['right'].apply(path_leaf)
print(data.head()) #returns first 5 rows of the sheet

num_bins = 25
samples_per_bin = 100
hist, bins = np.histogram(data['steering'], num_bins)
center = (bins[:-1] + bins[1:]) * 0.5
#plt.bar(center, hist, 0.05)
#plt.plot((np.min(data['steering']), np.max(data['steering'])), (samples_per_bin,samples_per_bin))
#using abv we can set threshold

#balancing the data
print('total data', len(data))
remove_list = []
for j in range(num_bins):
    list_ = []
    for i in range(len(data['steering'])):
        if data['steering'][i] >= bins[j] and data['steering'][i] <= bins[j+1]:
            list_.append(i)
    list_ = shuffle(list_)
    list_ = list_[samples_per_bin:]
    remove_list.extend(list_)

print('removed:', len(remove_list))
data.drop(data.index[remove_list], inplace=True)
print('remaining:', len(data))
hist, _ = np.histogram(data['steering'], num_bins)
#plt.bar(center, hist, 0.05)
#plt.plot((np.min(data['steering']), np.max(data['steering'])), (samples_per_bin,samples_per_bin))

#unpacking the images and steering angles
def load_image_steering(datadir, df):
    image_path =[]
    steering =[]
    for i in range(len(data)):
        indexed_data = data.iloc[i]
        center, left, right, = indexed_data[0], indexed_data[1], indexed_data[2]
        image_path.append(os.path.join(datadir, center.strip())) # strip function eliminates the space in the data if any
        steering.append(float(indexed_data[3]))
    image_path = np.asarray(image_path)
    steering = np.asarray(steering)
    return image_path, steering

image_path, steering = load_image_steering('C:\\Users\\HP\\PycharmProjects\\IP\\Cardata_BC\\IMG', data)


#splitting into training and validation sets
X_train, X_valid, y_train, y_valid = train_test_split(image_path, steering,  test_size= 0.2, random_state= 6)
#print('Training Samples: {}\nValid Samples: {} '.format(len(X_train), len(X_valid)))

#fig, axs = plt.subplots(1, 2, figsize=(12, 4))
#axs[0].hist(y_train, bins= num_bins, width= 0.05, color= 'blue' )
#axs[0].set_title('Training Set')
#axs[1].hist(y_valid, bins= num_bins, width= 0.05, color= 'red' )
#axs[1].set_title('Validation Set')

#data Augmentation
def zoom(image):
    zoom = iaa.Affine(scale = (1, 1.3))
    image = zoom.augment_image(image)
    return image

#preprocessing the images
def img_preprocess(img):
    img = mpimg.imread(img)
    img = img[60:135, :, :] #image slicing in the required directions
    img = cv2.cvtColor(img, cv2.COLOR_RGB2YUV)
    img = cv2.GaussianBlur(img, (3, 3), 0)
    img = cv2.resize(img, (200, 66)) #size demanded by NVIDIA model
    img = img/255
    return img

#just for checking the random image output after preprocessing
#image = image_path[100]
#original_image = mpimg.imread(image)
#preprocessed_image = img_preprocess(image)
#fig, axs = plt.subplots(1, 2, figsize=(15,10))
#fig.tight_layout()
#axs[0].imshow(original_image)
#axs[0].set_title('original image')
#axs[1].imshow(preprocessed_image)
#axs[1].set_title('preprocessed image')

X_train = np.array(list(map(img_preprocess, X_train)))
X_valid = np.array(list(map(img_preprocess, X_valid)))

#Our Neural Network
def nvidia_model():
    model = Sequential()
    model.add(Conv2D(24, (5, 5), strides = (2,2), input_shape= (66, 200, 3), activation = 'elu'))
    model.add(Conv2D(36, (5, 5), strides = (2,2), activation= 'elu'))
    model.add(Conv2D(48, (5, 5), strides = (2,2), activation='elu'))
    model.add(Conv2D(64, (3, 3), activation='elu'))
    model.add(Conv2D(64, (3, 3), activation='elu'))
    model.add(Dropout(0.5))

    model.add(Flatten())
    model.add(Dense(100, activation = 'elu'))
    model.add(Dropout(0.5))

    model.add(Dense(50, activation = 'elu'))
    model.add(Dropout(0.5))

    model.add(Dense(10, activation = 'elu'))
    model.add(Dropout(0.5))

    model.add(Dense(1))
    model.compile(Adam(lr = 1e-3), loss = 'mse')
    return model

model = nvidia_model()
print(model.summary())

history = model.fit(X_train, y_train, epochs = 30, validation_data= (X_valid, y_valid), batch_size= 100, verbose= 1, shuffle= 1)

#saving the model
#model.save('C:\\Users\\HP\\OneDrive\\Desktop\\Behaviour Cloning')

plt.show()





